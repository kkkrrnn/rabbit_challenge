{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lecture_chap1_exercise_public_shakyo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6td9S-Yi363W",
        "outputId": "7dee2215-9342-41a5-e442-1f678ce8150c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.4.0\n",
            "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4 MB 5.5 kB/s \n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 0.4.1\n",
            "    Uninstalling torch-0.4.1:\n",
            "      Successfully uninstalled torch-0.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.4.0\n",
            "1.4.0\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.4.0\n",
        "\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/9narw5x4uizmehh/utils.py\n",
        "!mkdir images data\n",
        "\n",
        "# data取得\n",
        "!wget https://www.dropbox.com/s/o4kyc52a8we25wy/dev.en -P data/\n",
        "!wget https://www.dropbox.com/s/kdgskm5hzg6znuc/dev.ja -P data/\n",
        "!wget https://www.dropbox.com/s/gyyx4gohv9v65uh/test.en -P data/\n",
        "!wget https://www.dropbox.com/s/hotxwbgoe2n013k/test.ja -P data/\n",
        "!wget https://www.dropbox.com/s/5lsftkmb20ay9e1/train.en -P data/\n",
        "!wget https://www.dropbox.com/s/ak53qirssci6f1j/train.ja -P data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3bx0OiU4Mi1",
        "outputId": "3096af5a-7109-429d-cf59-f079a7093ab7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-03 11:30:11--  https://www.dropbox.com/s/9narw5x4uizmehh/utils.py\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/9narw5x4uizmehh/utils.py [following]\n",
            "--2022-01-03 11:30:12--  https://www.dropbox.com/s/raw/9narw5x4uizmehh/utils.py\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uce060bfa4b95c11db57a2061910.dl.dropboxusercontent.com/cd/0/inline/BdFhl-1oFR_cj8l4Ook_N4fFkJwHUok0O0aqq7Qsdcdh7zzzAfd4-swK8LpXBtOOBT0j-yxSsvkiY50W-2dnD_kkJSFe4K6gnFIrc6qfUNRH77ONT68pRO4FclV74WrXHFEl7S4t3V_MuhWFBhp2a-kT/file# [following]\n",
            "--2022-01-03 11:30:12--  https://uce060bfa4b95c11db57a2061910.dl.dropboxusercontent.com/cd/0/inline/BdFhl-1oFR_cj8l4Ook_N4fFkJwHUok0O0aqq7Qsdcdh7zzzAfd4-swK8LpXBtOOBT0j-yxSsvkiY50W-2dnD_kkJSFe4K6gnFIrc6qfUNRH77ONT68pRO4FclV74WrXHFEl7S4t3V_MuhWFBhp2a-kT/file\n",
            "Resolving uce060bfa4b95c11db57a2061910.dl.dropboxusercontent.com (uce060bfa4b95c11db57a2061910.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601b:15::a27d:80f\n",
            "Connecting to uce060bfa4b95c11db57a2061910.dl.dropboxusercontent.com (uce060bfa4b95c11db57a2061910.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 949 [text/plain]\n",
            "Saving to: ‘utils.py.2’\n",
            "\n",
            "utils.py.2          100%[===================>]     949  --.-KB/s    in 0s      \n",
            "\n",
            "2022-01-03 11:30:12 (91.9 MB/s) - ‘utils.py.2’ saved [949/949]\n",
            "\n",
            "mkdir: cannot create directory ‘images’: File exists\n",
            "mkdir: cannot create directory ‘data’: File exists\n",
            "--2022-01-03 11:30:13--  https://www.dropbox.com/s/o4kyc52a8we25wy/dev.en\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/o4kyc52a8we25wy/dev.en [following]\n",
            "--2022-01-03 11:30:13--  https://www.dropbox.com/s/raw/o4kyc52a8we25wy/dev.en\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucae72cb0ad4bafb179e99782add.dl.dropboxusercontent.com/cd/0/inline/BdHumqJsnLuvre35aDhjcEECTTNzP6gAJovTPAxuDHwk1rBPsy_p5XxPvSK2DKyLo0db-mEPua_lT8_AWvtMhuCRwOBR8BXH7UHcfKjSkk9qbUc96ZOWfBGXnWuaxA0QGi83C-QANqN6XbtPl7pOR4De/file# [following]\n",
            "--2022-01-03 11:30:13--  https://ucae72cb0ad4bafb179e99782add.dl.dropboxusercontent.com/cd/0/inline/BdHumqJsnLuvre35aDhjcEECTTNzP6gAJovTPAxuDHwk1rBPsy_p5XxPvSK2DKyLo0db-mEPua_lT8_AWvtMhuCRwOBR8BXH7UHcfKjSkk9qbUc96ZOWfBGXnWuaxA0QGi83C-QANqN6XbtPl7pOR4De/file\n",
            "Resolving ucae72cb0ad4bafb179e99782add.dl.dropboxusercontent.com (ucae72cb0ad4bafb179e99782add.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to ucae72cb0ad4bafb179e99782add.dl.dropboxusercontent.com (ucae72cb0ad4bafb179e99782add.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17054 (17K) [text/plain]\n",
            "Saving to: ‘data/dev.en.2’\n",
            "\n",
            "dev.en.2            100%[===================>]  16.65K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2022-01-03 11:30:13 (4.52 MB/s) - ‘data/dev.en.2’ saved [17054/17054]\n",
            "\n",
            "--2022-01-03 11:30:13--  https://www.dropbox.com/s/kdgskm5hzg6znuc/dev.ja\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/kdgskm5hzg6znuc/dev.ja [following]\n",
            "--2022-01-03 11:30:14--  https://www.dropbox.com/s/raw/kdgskm5hzg6znuc/dev.ja\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc80fed109f184a754698efcc6eb.dl.dropboxusercontent.com/cd/0/inline/BdEMCE-DMKdG2TaS69T1ilw6ymWwM9SjJV_iM4zDngbfl67LO-Wty_8wohlc3wcWsaezAchV1LraoB8ByP8M0ti49EDWv-tqGj83-M6k5PvumnBPuEvltAhAskXmcK_QwHlaJFVQXP4sNdW7ADwEb7bj/file# [following]\n",
            "--2022-01-03 11:30:14--  https://uc80fed109f184a754698efcc6eb.dl.dropboxusercontent.com/cd/0/inline/BdEMCE-DMKdG2TaS69T1ilw6ymWwM9SjJV_iM4zDngbfl67LO-Wty_8wohlc3wcWsaezAchV1LraoB8ByP8M0ti49EDWv-tqGj83-M6k5PvumnBPuEvltAhAskXmcK_QwHlaJFVQXP4sNdW7ADwEb7bj/file\n",
            "Resolving uc80fed109f184a754698efcc6eb.dl.dropboxusercontent.com (uc80fed109f184a754698efcc6eb.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601b:15::a27d:80f\n",
            "Connecting to uc80fed109f184a754698efcc6eb.dl.dropboxusercontent.com (uc80fed109f184a754698efcc6eb.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27781 (27K) [text/plain]\n",
            "Saving to: ‘data/dev.ja.2’\n",
            "\n",
            "dev.ja.2            100%[===================>]  27.13K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-01-03 11:30:15 (816 KB/s) - ‘data/dev.ja.2’ saved [27781/27781]\n",
            "\n",
            "--2022-01-03 11:30:15--  https://www.dropbox.com/s/gyyx4gohv9v65uh/test.en\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/gyyx4gohv9v65uh/test.en [following]\n",
            "--2022-01-03 11:30:15--  https://www.dropbox.com/s/raw/gyyx4gohv9v65uh/test.en\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc39ddb5856354d21408c482c75a.dl.dropboxusercontent.com/cd/0/inline/BdH7VRi11S6ZsoVQIniOX910TSS-ohoibAs1QflmqIS1GQnQttgL1KIupoVCVP7XtiLfMvytrN6zkun6HACC7Z5wPz8K4lZA7iQC9g_aN29QGBwA3OJjyQbASTDBz1V-me8uOPij0f6PkgeUfFBbb4PS/file# [following]\n",
            "--2022-01-03 11:30:15--  https://uc39ddb5856354d21408c482c75a.dl.dropboxusercontent.com/cd/0/inline/BdH7VRi11S6ZsoVQIniOX910TSS-ohoibAs1QflmqIS1GQnQttgL1KIupoVCVP7XtiLfMvytrN6zkun6HACC7Z5wPz8K4lZA7iQC9g_aN29QGBwA3OJjyQbASTDBz1V-me8uOPij0f6PkgeUfFBbb4PS/file\n",
            "Resolving uc39ddb5856354d21408c482c75a.dl.dropboxusercontent.com (uc39ddb5856354d21408c482c75a.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc39ddb5856354d21408c482c75a.dl.dropboxusercontent.com (uc39ddb5856354d21408c482c75a.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17301 (17K) [text/plain]\n",
            "Saving to: ‘data/test.en.2’\n",
            "\n",
            "test.en.2           100%[===================>]  16.90K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2022-01-03 11:30:16 (4.18 MB/s) - ‘data/test.en.2’ saved [17301/17301]\n",
            "\n",
            "--2022-01-03 11:30:16--  https://www.dropbox.com/s/hotxwbgoe2n013k/test.ja\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/hotxwbgoe2n013k/test.ja [following]\n",
            "--2022-01-03 11:30:16--  https://www.dropbox.com/s/raw/hotxwbgoe2n013k/test.ja\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucf255d3f3b18b15e73a58d11049.dl.dropboxusercontent.com/cd/0/inline/BdF7lgEFGHqgTedroJek6bEj-tH2ngDuaRuSu7wOie6r0YQSGbuidlnyo-dA5DsnVSzhyucVBJesfZi4ITQ5w0j_9SHwsx5slOEJ4oHJuJj7g6B0watBXBSa7gmrVFqroEbtirGpdgVTCCSGgYabp_Yw/file# [following]\n",
            "--2022-01-03 11:30:16--  https://ucf255d3f3b18b15e73a58d11049.dl.dropboxusercontent.com/cd/0/inline/BdF7lgEFGHqgTedroJek6bEj-tH2ngDuaRuSu7wOie6r0YQSGbuidlnyo-dA5DsnVSzhyucVBJesfZi4ITQ5w0j_9SHwsx5slOEJ4oHJuJj7g6B0watBXBSa7gmrVFqroEbtirGpdgVTCCSGgYabp_Yw/file\n",
            "Resolving ucf255d3f3b18b15e73a58d11049.dl.dropboxusercontent.com (ucf255d3f3b18b15e73a58d11049.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to ucf255d3f3b18b15e73a58d11049.dl.dropboxusercontent.com (ucf255d3f3b18b15e73a58d11049.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27793 (27K) [text/plain]\n",
            "Saving to: ‘data/test.ja.2’\n",
            "\n",
            "test.ja.2           100%[===================>]  27.14K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-01-03 11:30:16 (1.37 MB/s) - ‘data/test.ja.2’ saved [27793/27793]\n",
            "\n",
            "--2022-01-03 11:30:17--  https://www.dropbox.com/s/5lsftkmb20ay9e1/train.en\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/5lsftkmb20ay9e1/train.en [following]\n",
            "--2022-01-03 11:30:17--  https://www.dropbox.com/s/raw/5lsftkmb20ay9e1/train.en\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucccaa705c15c3ca30c77305a076.dl.dropboxusercontent.com/cd/0/inline/BdEbLwxNHuTc54FdbCE-jseZdq21fXxtZnuS-KOKjn1gQIOU2cLnfdAxdb7HYUGKCa9LpmMbzJFJBKWBAlbZIHu2xDrSh1ZSWSP1ejI9Jzj__G1108wSayHdlOdSqn7zXE2vO9UgbIoAcMvC2NsGk1P7/file# [following]\n",
            "--2022-01-03 11:30:17--  https://ucccaa705c15c3ca30c77305a076.dl.dropboxusercontent.com/cd/0/inline/BdEbLwxNHuTc54FdbCE-jseZdq21fXxtZnuS-KOKjn1gQIOU2cLnfdAxdb7HYUGKCa9LpmMbzJFJBKWBAlbZIHu2xDrSh1ZSWSP1ejI9Jzj__G1108wSayHdlOdSqn7zXE2vO9UgbIoAcMvC2NsGk1P7/file\n",
            "Resolving ucccaa705c15c3ca30c77305a076.dl.dropboxusercontent.com (ucccaa705c15c3ca30c77305a076.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to ucccaa705c15c3ca30c77305a076.dl.dropboxusercontent.com (ucccaa705c15c3ca30c77305a076.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1701356 (1.6M) [text/plain]\n",
            "Saving to: ‘data/train.en.2’\n",
            "\n",
            "train.en.2          100%[===================>]   1.62M  9.72MB/s    in 0.2s    \n",
            "\n",
            "2022-01-03 11:30:18 (9.72 MB/s) - ‘data/train.en.2’ saved [1701356/1701356]\n",
            "\n",
            "--2022-01-03 11:30:18--  https://www.dropbox.com/s/ak53qirssci6f1j/train.ja\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/ak53qirssci6f1j/train.ja [following]\n",
            "--2022-01-03 11:30:18--  https://www.dropbox.com/s/raw/ak53qirssci6f1j/train.ja\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc950f8b77ecb302c9de203965e4.dl.dropboxusercontent.com/cd/0/inline/BdG7uwmS35ZItHMKtzbvXizJbT8iTkV6kohDUyNtoXw87JAE3kLivKsfuPbTg0Y8IQomE7GTSHLb2gck_eDonM0VDF4SM0ZNZPsxRkNcTPUGW7uZWQjfaIsG1gUOL0Z4-7dyFvpQ2R_Tx2GOJ2ba0Hf1/file# [following]\n",
            "--2022-01-03 11:30:18--  https://uc950f8b77ecb302c9de203965e4.dl.dropboxusercontent.com/cd/0/inline/BdG7uwmS35ZItHMKtzbvXizJbT8iTkV6kohDUyNtoXw87JAE3kLivKsfuPbTg0Y8IQomE7GTSHLb2gck_eDonM0VDF4SM0ZNZPsxRkNcTPUGW7uZWQjfaIsG1gUOL0Z4-7dyFvpQ2R_Tx2GOJ2ba0Hf1/file\n",
            "Resolving uc950f8b77ecb302c9de203965e4.dl.dropboxusercontent.com (uc950f8b77ecb302c9de203965e4.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:601f:15::a27d:90f\n",
            "Connecting to uc950f8b77ecb302c9de203965e4.dl.dropboxusercontent.com (uc950f8b77ecb302c9de203965e4.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2784447 (2.7M) [text/plain]\n",
            "Saving to: ‘data/train.ja.2’\n",
            "\n",
            "train.ja.2          100%[===================>]   2.66M  6.01MB/s    in 0.4s    \n",
            "\n",
            "2022-01-03 11:30:19 (6.01 MB/s) - ‘data/train.ja.2’ saved [2784447/2784447]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blzY1f2O4YJI",
        "outputId": "bfa8cfc5-442c-4444-a0df-3127e54b2efe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.en\t  dev.ja    test.en    test.ja\t  train.en    train.ja\n",
            "dev.en.1  dev.ja.1  test.en.1  test.ja.1  train.en.1  train.ja.1\n",
            "dev.en.2  dev.ja.2  test.en.2  test.ja.2  train.en.2  train.ja.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from nltk import bleu_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
        "from utils import Vocab\n",
        "\n",
        "# デバイスの設定\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "torch.manual_seed(1)\n",
        "random_state = 42\n",
        "\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtORnImz4gAl",
        "outputId": "25c7d298-59c0-4a87-a184-f25f7c1327a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. データセットの準備"
      ],
      "metadata": {
        "id": "yx9Q_TmV4jJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 data/train.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E712zgh4ppB",
        "outputId": "a9668693-a63e-482b-ed78-da665afe859b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i can 't tell who will arrive first .\n",
            "many animals have been destroyed by men .\n",
            "i 'm in the tennis club .\n",
            "emi looks happy .\n",
            "please bear this fact in mind .\n",
            "she takes care of my children .\n",
            "we want to be international .\n",
            "you ought not to break your promise .\n",
            "when you cross the street , watch out for cars .\n",
            "i have nothing to live for .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 data/train.ja"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLX2qKXU4sCz",
        "outputId": "f945670b-ea1a-4d3c-e0df-ff78d5ac13c4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "誰 が 一番 に 着 く か 私 に は 分か り ま せ ん 。\n",
            "多く の 動物 が 人間 に よ っ て 滅ぼ さ れ た 。\n",
            "私 は テニス 部員 で す 。\n",
            "エミ は 幸せ そう に 見え ま す 。\n",
            "この 事実 を 心 に 留め て お い て 下さ い 。\n",
            "彼女 は 私 たち の 世話 を し て くれ る 。\n",
            "私 達 は 国際 人 に な り た い と 思 い ま す 。\n",
            "約束 を 破 る べ き で は あ り ま せ ん 。\n",
            "道路 を 横切 る とき は 車 に 注意 し なさ い 。\n",
            "私 に は 生き 甲斐 が な い 。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "24gmrTYL4vrj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1 データの読み込みと単語の分割"
      ],
      "metadata": {
        "id": "XilsQlgJ42mW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# テキストファイルからデータを読み込み\n",
        "def load_data(file_path):\n",
        "  data = []\n",
        "  for line in open(file_path, encoding='utf-8'):\n",
        "    words = line.strip().split()  # スペースで単語を分割\n",
        "    data.append(words)\n",
        "  return data"
      ],
      "metadata": {
        "id": "bNfJvxmB47hL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = load_data('./data/train.en')\n",
        "train_Y = load_data('./data/train.ja')\n",
        "\n",
        "# 訓練データと検証データに分割\n",
        "train_X, valid_X, train_Y, valid_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=random_state)"
      ],
      "metadata": {
        "id": "gxD6ZeE65OS0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_X[0])\n",
        "print(valid_X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbRDqqvI5kIc",
        "outputId": "e37a0a40-0621-4788-c162-956dec184efb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['where', 'shall', 'we', 'eat', 'tonight', '?']\n",
            "['you', 'may', 'extend', 'your', 'stay', 'in', 'tokyo', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2 単語辞書の作成"
      ],
      "metadata": {
        "id": "3Ad1ejcP5pO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データセットに登場する各単語にIDを割り振る\n",
        "# 特殊トークンの定義\n",
        "PAD_TOKEN = '<PAD>'\n",
        "BOS_TOKEN = '<S>'\n",
        "EOS_TOKEN = '</S>'\n",
        "UNK_TOKEN = '<UNK>'\n",
        "PAD = 0\n",
        "BOS = 1\n",
        "EOS = 2\n",
        "UNK = 3"
      ],
      "metadata": {
        "id": "d5trv9Gv5uuP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MIN_COUNT = 2  # 語彙に含める単語の最低出現回数\n",
        "\n",
        "word2id = {\n",
        "    PAD_TOKEN : PAD,\n",
        "    BOS_TOKEN : BOS,\n",
        "    EOS_TOKEN : EOS,\n",
        "    UNK_TOKEN : UNK\n",
        "}\n",
        "\n",
        "# 単語辞書を作成\n",
        "vocab_X = Vocab(word2id=word2id)\n",
        "vocab_Y = Vocab(word2id=word2id)\n",
        "vocab_X.build_vocab(train_X, min_count=MIN_COUNT)\n",
        "vocab_Y.build_vocab(train_Y, min_count=MIN_COUNT)"
      ],
      "metadata": {
        "id": "dNsmR0ef6TPO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size_X = len(vocab_X.id2word)\n",
        "vocab_size_Y = len(vocab_Y.id2word)\n",
        "print('入力言語の語彙数：', vocab_size_X)\n",
        "print('出力言語の語彙数：', vocab_size_Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x7JITW26u5A",
        "outputId": "d474fa6c-6ad7-4099-911b-055c79cba6c1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "入力言語の語彙数： 3725\n",
            "出力言語の語彙数： 4405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "２ テンソルへの変換"
      ],
      "metadata": {
        "id": "RfZZNYHV6yIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.１ IDへの変換\n"
      ],
      "metadata": {
        "id": "F1EbojxC65Yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 文章を単語IDのリストに変換\n",
        "def sentence_to_ids(vocab, sentence):\n",
        "  ids = [vocab.word2id.get(word, UNK) for word in sentence]\n",
        "  ids += [EOS]  # EOSを加える\n",
        "  return ids"
      ],
      "metadata": {
        "id": "wd_uLZem7AuF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = [sentence_to_ids(vocab_X, sentence) for sentence in train_X]\n",
        "train_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in train_Y]\n",
        "valid_X = [sentence_to_ids(vocab_X, sentence) for sentence in valid_X]\n",
        "valid_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in valid_Y]"
      ],
      "metadata": {
        "id": "Cu9HqDc972af"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_X[0])\n",
        "print(valid_X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rwGtVVg76mr",
        "outputId": "258f9be4-f7b1-4b5a-fecd-72d24ceeed3e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[132, 321, 28, 290, 367, 12, 2]\n",
            "[8, 93, 3532, 36, 236, 13, 284, 4, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2 DataLoaderの定義"
      ],
      "metadata": {
        "id": "Q0fI3Hoh8N6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 系列が指定の文長になるように末尾をパディング\n",
        "def pad_seq(seq, max_length):\n",
        "  res = seq + [PAD for i in range(max_length - len(seq))]\n",
        "  return res"
      ],
      "metadata": {
        "id": "1TzjKGW08TyF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader(object):\n",
        "  def __init__(self, X, Y, batch_size, shuffle=False):\n",
        "    '''\n",
        "    :param X : list, 入力言語の文章（単語IDのリスト）のリスト\n",
        "    :param Y : list, 出力言語の文章（単語IDのリスト）のリスト\n",
        "    :param batch_size : int, バッチサイズ\n",
        "    :param shuffle: bool, サンプルの順番をシャッフルするか否か\n",
        "    '''\n",
        "    self.data = list(zip(X, Y))\n",
        "    self.batch_size = batch_size\n",
        "    self.shuffle = shuffle\n",
        "    self.start_index = 0\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    if self.shuffle:  # サンプルの順番をシャッフル\n",
        "      self.data = shuffle(self.data, random_state=random_state)\n",
        "    self.start_index = 0  # ポインタの位置を初期化\n",
        "  \n",
        "  def __iter__(self):\n",
        "    return self\n",
        "\n",
        "  def __next__(self):\n",
        "    # ポインタが最後まで到達したら初期化\n",
        "    if self.start_index >= len(self.data):\n",
        "      self.reset()\n",
        "      raise StopIteration()\n",
        "    \n",
        "    # バッチを取得\n",
        "    seqs_X, seqs_Y = zip(*self.data[self.start_index:self.start_index+self.batch_size])\n",
        "    # 入力系列seq_Xの文章の長さ順（降順）に系列ペアをソート\n",
        "    seq_pairs = sorted(zip(seqs_X, seqs_Y), key=lambda p: len(p[0]), reverse=True)\n",
        "    seqs_X, seqs_Y = zip(*seq_pairs)\n",
        "\n",
        "    # 短い系列の末尾をパディング\n",
        "    lengths_X = [len(s) for s in seqs_X]\n",
        "    lengths_Y = [len(s) for s in seqs_Y]\n",
        "    max_length_X = max(lengths_X)\n",
        "    max_length_Y = max(lengths_Y)\n",
        "    padded_X = [pad_seq(s, max_length_X) for s in seqs_X]\n",
        "    padded_Y = [pad_seq(s, max_length_Y) for s in seqs_Y]\n",
        "\n",
        "    # tensor に変換し転置する\n",
        "    batch_X = torch.tensor(padded_X, dtype=torch.long, device=device).transpose(0,1)\n",
        "    batch_Y = torch.tensor(padded_Y, dtype=torch.long, device=device).transpose(0,1)\n",
        "\n",
        "    # ポインタを更新\n",
        "    self.start_index += self.batch_size\n",
        "\n",
        "    return batch_X, batch_Y, lengths_X"
      ],
      "metadata": {
        "id": "Dx_9yJDD8ytv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. モデルの構築\n",
        "\n",
        "EncoderとDecoderのRNNを定義\n",
        "\n"
      ],
      "metadata": {
        "id": "x9RR6GAq_9zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 系列長がそれぞれ4,3,2の3つのサンプルからなるバッチを作成\n",
        "batch = [[1,2,3,4], [5,6,7], [8,9]]\n",
        "lengths = [len(sample) for sample in batch]\n",
        "print('各サンプルの系列長:', lengths)\n",
        "print()\n",
        "\n",
        "# 最大系列長に合うように各サンプルをpadding\n",
        "_max_length = max(lengths)\n",
        "padded = torch.tensor([pad_seq(sample, _max_length) for sample in batch])\n",
        "print('paddingされたテンソル:\\n', padded)\n",
        "padded = padded.transpose(0,1)  # (max_length, batch_size)に転置\n",
        "print('padding & 転置されたテンソル:\\n', padded)\n",
        "print('padding & 転置されたテンソルのサイズ:\\n', padded.size())\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLuurAy4AEom",
        "outputId": "c90d6301-d59a-4962-9f24-81a394e3ffa6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "各サンプルの系列長: [4, 3, 2]\n",
            "\n",
            "paddingされたテンソル:\n",
            " tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 0],\n",
            "        [8, 9, 0, 0]])\n",
            "padding & 転置されたテンソル:\n",
            " tensor([[1, 5, 8],\n",
            "        [2, 6, 9],\n",
            "        [3, 7, 0],\n",
            "        [4, 0, 0]])\n",
            "padding & 転置されたテンソルのサイズ:\n",
            " torch.Size([4, 3])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PackedSequenceに変換(テンソルをRNNに入力する前に適用する)\n",
        "packed = pack_padded_sequence(padded, lengths=lengths)\n",
        "print('PackedSequenceのインスタンス:\\n', packed)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2QateB_ASll",
        "outputId": "7cda6e71-740e-4da1-eb97-edb168005230"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PackedSequenceのインスタンス:\n",
            " PackedSequence(data=tensor([1, 5, 8, 2, 6, 9, 3, 7, 4]), batch_sizes=tensor([3, 3, 2, 1]), sorted_indices=None, unsorted_indices=None)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RNNに入力（省略）\n",
        "output = packed\n",
        "\n",
        "# テンソルに戻す(RNNの出力に対して適用する)\n",
        "output, _length = pad_packed_sequence(output)\n",
        "print(output)\n",
        "print(_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ViEoxS-A2QE",
        "outputId": "49a8ca87-4940-4b7c-aa8a-26fa29a787fb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 5, 8],\n",
            "        [2, 6, 9],\n",
            "        [3, 7, 0],\n",
            "        [4, 0, 0]])\n",
            "tensor([4, 3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder"
      ],
      "metadata": {
        "id": "gLtsvm74BVdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    '''\n",
        "    :param input_size : int, 入力言語の語彙数\n",
        "    :param hidden_size : 隠れ層のユニット数\n",
        "    '''\n",
        "    super(Encoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size, padding_idx=PAD)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "  def forward(self, seqs, input_lengths, hidden=None):\n",
        "    '''\n",
        "    :param seqs : tensor, 入力のバッチ, size=(max_length, batch_size)\n",
        "    :param input_lengths : 入力のバッチの各サンプルの文長\n",
        "    :param hidden : tensor, 隠れ状態の初期値, Noneの場合は0で初期化される\n",
        "    :return output : tensor, Encoderの出力, size=(max_length, batch_size, hidden_size)\n",
        "    :return hidden : tensor, Encoderの隠れ状態, size=(1, batch_size, hidden_size)\n",
        "    '''\n",
        "    emb = self.embedding(seqs)\n",
        "    packed = pack_padded_sequence(emb, input_lengths)  # PackedSequenceオブジェクトに変換\n",
        "    output, hidden = self.gru(packed, hidden)\n",
        "    output, _ = pad_packed_sequence(output)\n",
        "    return output, hidden"
      ],
      "metadata": {
        "id": "fPfb6PZMBjVw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decorder"
      ],
      "metadata": {
        "id": "6a4Xh2ioDP-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size):\n",
        "    '''\n",
        "    :param hidden_size : 隠れ層のユニット数\n",
        "    :param output_size : int, 出力言語の語彙数\n",
        "    :param dropout : float, ドロップアウト率\n",
        "    '''\n",
        "    super(Decoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=PAD)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, seqs, hidden):\n",
        "    '''\n",
        "    :param seqs: tensor, 入力のバッチ, size=(1, batch_size)\n",
        "    :param hidden: tensor, 隠れ状態の初期値, Noneの場合は0で初期化される\n",
        "    :return output: tensor, Decoderの出力, size=(1, batch_size, output_size)\n",
        "    :return hidden: tensor, Decoderの隠れ状態, size=(1, batch_size, hidden_size)\n",
        "    '''\n",
        "    emb = self.embedding(seqs)\n",
        "    output, hidden = self.gru(emb, hidden)\n",
        "    output = self.out(output)\n",
        "    return output, hidden"
      ],
      "metadata": {
        "id": "06kJzDw6DUeR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EncoderDecoder"
      ],
      "metadata": {
        "id": "XspIm3zHEQPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "  '''\n",
        "  EncoderとDecoderの処理をまとめる\n",
        "  '''\n",
        "  def __init__(self, input_size, output_size, hidden_size):\n",
        "    '''\n",
        "    :param input_size: int, 入力言語の語彙数\n",
        "    :param output_size: int, 出力言語の語彙数\n",
        "    :param hidden_size: int, 隠れ層のユニット数    \n",
        "    '''\n",
        "    super(EncoderDecoder, self).__init__()\n",
        "    self.encoder = Encoder(input_size, hidden_size)\n",
        "    self.decoder = Decoder(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, batch_X, lengths_X, max_length, batch_Y=None, use_teacher_forcing=False):\n",
        "    '''\n",
        "    :param batch_X: tensor, 入力系列のバッチ, size=(max_length, batch_size)\n",
        "    :param lengths_X: list, 入力系列のバッチ内の各サンプルの文長\n",
        "    :param max_length: int, Decoderの最大文長\n",
        "    :param batch_Y: tensor, Decoderで用いるターゲット系列\n",
        "    :param use_teacher_forcing: Decoderでターゲット系列を入力とするフラグ\n",
        "    :return decoder_outputs: tensor, Decoderの出力, \n",
        "        size=(max_length, batch_size, self.decoder.output_size)\n",
        "    '''\n",
        "    # encoderに系列を入力（複数時刻をまとめて処理）\n",
        "    _, encoder_hidden = self.encoder(batch_X, lengths_X)\n",
        "    _batch_size = batch_X.size(1)\n",
        "\n",
        "    # decoderの入力と隠れ層の初期状態を定義\n",
        "    decoder_input = torch.tensor([BOS] * _batch_size, dtype=torch.long, device=device)  # 最初の入力にはBOSを使用する\n",
        "    decoder_input = decoder_input.unsqueeze(0)  # (1, batch_size)\n",
        "    decoder_hidden = encoder_hidden  # Encoderの最終隠れ状態を取得\n",
        "\n",
        "    # decoderの出力ホルダーを定義\n",
        "    decoder_outputs = torch.zeros(max_length, _batch_size, self.decoder.output_size, device=device)\n",
        "\n",
        "    # 各時刻ごとに処理\n",
        "    for t in range(max_length):\n",
        "      decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "      decoder_outputs[t] = decoder_output\n",
        "      # 次の時刻のdecoderの入力を決定\n",
        "      if use_teacher_forcing and batch_Y is not None:  # teacher forceの場合、ターゲット系列を用いる\n",
        "        decoder_input = batch_Y[t].unsqueeze(0)\n",
        "      else:  # teacher forceでない場合、自身の出力を用いる\n",
        "        decoder_input = decoder_output.max(-1)[1]\n",
        "\n",
        "    return decoder_outputs\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Wsz92lNXEki4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. 訓練"
      ],
      "metadata": {
        "id": "_PK_sgrOIJYu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1 損失関数の定義"
      ],
      "metadata": {
        "id": "BKOt3s45MmXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mce = nn.CrossEntropyLoss(size_average=False, ignore_index=PAD)  # PADを無視する\n",
        "def masked_cross_entropy(logits, target):\n",
        "  logits_flat = logits.view(-1, logits.size(-1))\n",
        "  target_flat = target.view(-1)\n",
        "  return mce(logits_flat, target_flat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LyAPzbYMpIQ",
        "outputId": "dad84aa8-c430-477f-98fc-1a3770b9cf1e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2 学習"
      ],
      "metadata": {
        "id": "cWjYC5nQNEoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ハイパーパラメータの設定\n",
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "lr = 1e-3  # 学習率\n",
        "teacher_forcing_rate = 0.2  # Teacher Forcingを行う確率\n",
        "ckpt_path = 'model.pth'  # 学習済みモデルを保存するパス\n",
        "\n",
        "model_args = {\n",
        "    'input_size': vocab_size_X,\n",
        "    'output_size': vocab_size_Y,\n",
        "    'hidden_size': 256\n",
        "}"
      ],
      "metadata": {
        "id": "PS6HeZLeNH81"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データローダーを定義\n",
        "train_dataloader = DataLoader(train_X, train_Y, batch_size=batch_size, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_X, valid_Y, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# モデルとoptimizerを定義\n",
        "model = EncoderDecoder(**model_args).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "G5O6TuNxNj9Z"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 損失関数を計算する関数\n",
        "def compute_loss(batch_X, batch_Y, lengths_X, model, optimizer=None, is_train=True):\n",
        "  model.train(is_train)  # train/evalモードの切り替え\n",
        "\n",
        "  # 一定確率でTeacher　Forcingを行う\n",
        "  use_teacher_forcing = is_train and(random.random() < teacher_forcing_rate)\n",
        "  max_length = batch_Y.size(0)\n",
        "\n",
        "  # 推論\n",
        "  pred_Y = model(batch_X, lengths_X, max_length, batch_Y, use_teacher_forcing)\n",
        "  # 損失関数を計算\n",
        "  loss = masked_cross_entropy(pred_Y.contiguous(), batch_Y.contiguous())\n",
        "\n",
        "  if is_train:  # 訓練時はパラメータを更新\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  batch_Y = batch_Y.transpose(0, 1).contiguous().data.cpu().tolist()\n",
        "  pred = pred_Y.max(dim=-1)[1].data.cpu().numpy().T.tolist()\n",
        "\n",
        "  return loss.item(), batch_Y, pred"
      ],
      "metadata": {
        "id": "v2zix5wiOMS9"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_bleu(refs, hyps):\n",
        "  '''\n",
        "  BLEUスコアを計算する関数\n",
        "  :param refs: list, 参照訳。単語のリストのリスト (例： [['I', 'have', 'a', 'pen'], ...])\n",
        "  :param hyps: list, モデルの生成した訳。単語のリストのリスト (例： ['I', 'have', 'a', 'pen'])\n",
        "  :return: float, BLEUスコア(0~100)\n",
        "  '''\n",
        "  refs = [[ref[:ref.index(EOS)]] for ref in refs]  # EOSは評価しないで良いので切り捨てる。refsのほうは複数なのでlistが一個多くかかっている\n",
        "  hyps = [hyp[:hyp.index(EOS)] if EOS in hyp else hyp for hyp in hyps]\n",
        "  return 100 * bleu_score.corpus_bleu(refs, hyps)"
      ],
      "metadata": {
        "id": "Wy2gGn-NPkfh"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練\n",
        "best_valid_bleu = 0.\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  train_loss = 0.\n",
        "  train_refs = []\n",
        "  train_hyps = []\n",
        "  valid_loss = 0.\n",
        "  valid_refs = []\n",
        "  valid_hyps = []\n",
        "\n",
        "  # train\n",
        "  for batch in train_dataloader:\n",
        "    batch_X, batch_Y, lengths_X = batch\n",
        "    loss, gold, pred = compute_loss(batch_X, batch_Y, lengths_X, model, optimizer, is_train=True)\n",
        "    train_loss += loss\n",
        "    train_refs += gold\n",
        "    train_hyps += pred\n",
        "  \n",
        "  # valid\n",
        "  for batch in valid_dataloader:\n",
        "    batch_X, batch_Y, lengths_X = batch\n",
        "    loss, gold, pred = compute_loss(batch_X, batch_Y, lengths_X, model, is_train=False)\n",
        "    valid_loss += loss\n",
        "    valid_refs += gold\n",
        "    valid_hyps += pred\n",
        "  \n",
        "  # 損失をサンプル数で割って正規化\n",
        "  train_loss = np.sum(train_loss) / len(train_dataloader.data)\n",
        "  valid_loss = np.sum(valid_loss) / len(valid_dataloader.data)\n",
        "  # BLEUを計算\n",
        "  train_bleu = calc_bleu(train_refs, train_hyps)\n",
        "  valid_bleu = calc_bleu(valid_refs, valid_hyps)\n",
        "\n",
        "  # validationデータでBLEUが改善した場合にはモデルを保存\n",
        "  if valid_bleu > best_valid_bleu:\n",
        "    ckpt = model.state_dict()\n",
        "    torch.save(ckpt, ckpt_path)\n",
        "    best_valid_bleu = valid_bleu\n",
        "  \n",
        "  print('Epoch {}: train_loss: {:5.2f}  train_bleu: {:2.2f}  valid_loss: {:5.2f}  valid_bleu: {:2.2f}'.format(epoch, train_loss, train_bleu, valid_loss, valid_bleu))\n",
        "      \n",
        "  print('-'*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UpzRb4sP6tG",
        "outputId": "a07bb4a8-ac96-460d-f1d0-f03c3ade2b6e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train_loss: 52.28  train_bleu: 3.34  valid_loss: 48.86  valid_bleu: 3.83\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 2: train_loss: 44.90  train_bleu: 7.20  valid_loss: 44.58  valid_bleu: 7.78\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 3: train_loss: 40.62  train_bleu: 10.66  valid_loss: 42.18  valid_bleu: 11.00\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 4: train_loss: 37.50  train_bleu: 13.84  valid_loss: 40.81  valid_bleu: 13.06\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 5: train_loss: 34.88  train_bleu: 16.77  valid_loss: 40.13  valid_bleu: 13.62\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 6: train_loss: 33.04  train_bleu: 18.94  valid_loss: 39.74  valid_bleu: 14.94\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 7: train_loss: 31.45  train_bleu: 21.06  valid_loss: 39.86  valid_bleu: 15.14\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 8: train_loss: 30.13  train_bleu: 22.92  valid_loss: 39.94  valid_bleu: 16.22\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 9: train_loss: 28.80  train_bleu: 24.90  valid_loss: 40.88  valid_bleu: 18.67\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 10: train_loss: 27.89  train_bleu: 26.61  valid_loss: 40.44  valid_bleu: 17.18\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. 評価"
      ],
      "metadata": {
        "id": "_dubaJMTR2gU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習済みモデルの読み込み\n",
        "ckpt = torch.load(ckpt_path)\n",
        "model.load_state_dict(ckpt)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuRyptkPTzdj",
        "outputId": "b9c0b712-c8d0-4f8a-b790-79c42065f8e5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EncoderDecoder(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(3725, 256, padding_idx=0)\n",
              "    (gru): GRU(256, 256)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(4405, 256, padding_idx=0)\n",
              "    (gru): GRU(256, 256)\n",
              "    (out): Linear(in_features=256, out_features=4405, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ids_to_sentence(vocab, ids):\n",
        "  # IDのリストを単語のリストに変換する\n",
        "  return [vocab.id2word[_id] for _id in ids]\n",
        "\n",
        "def trim_eos(ids):\n",
        "  # IDのリストからEOS以降の単語を除外する\n",
        "  if EOS in ids:\n",
        "      return ids[:ids.index(EOS)]\n",
        "  else:\n",
        "      return ids"
      ],
      "metadata": {
        "id": "BuSMMOt_T-Xr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# テストデータの読み込み\n",
        "test_X = load_data('./data/dev.en')\n",
        "test_Y = load_data('./data/dev.ja')"
      ],
      "metadata": {
        "id": "lATIwnljUFZz"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_X = [sentence_to_ids(vocab_X, sentence) for sentence in test_X]\n",
        "test_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in test_Y]"
      ],
      "metadata": {
        "id": "TsicMqMWUFW4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(test_X, test_Y, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "aEeB98SbUFSi"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 生成\n",
        "batch_X, batch_Y, lengths_X = next(test_dataloader)\n",
        "sentence_X = ' '.join(ids_to_sentence(vocab_X, batch_X.data.cpu().numpy()[:-1, 0]))\n",
        "sentence_Y = ' '.join(ids_to_sentence(vocab_Y, batch_Y.data.cpu().numpy()[:-1, 0]))\n",
        "print('src: {}'.format(sentence_X))\n",
        "print('tgt: {}'.format(sentence_Y))\n",
        "\n",
        "output = model(batch_X, lengths_X, max_length=20)\n",
        "output = output.max(dim=-1)[1].view(-1).data.cpu().tolist()\n",
        "output_sentence = ' '.join(ids_to_sentence(vocab_Y, trim_eos(output)))\n",
        "output_sentence_without_trim = ' '.join(ids_to_sentence(vocab_Y, output))\n",
        "print('out: {}'.format(output_sentence))\n",
        "print('without trim: {}'.format(output_sentence_without_trim))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZYYuZVdUFP1",
        "outputId": "61f1730c-5e48-4f8b-c0e1-6fd8638be800"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src: show your own business .\n",
            "tgt: 自分 の 事 を しろ 。\n",
            "out: 自分 の 仕事 を を し て い 。 。\n",
            "without trim: 自分 の 仕事 を を し て い 。 。 </S> </S> </S> </S> </S> </S> </S> </S> </S> </S>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLEUを計算\n",
        "test_dataloader = DataLoader(test_X, test_Y, batch_size=1, shuffle=False)\n",
        "refs_list = []\n",
        "hyp_list = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "  batch_X, batch_Y, lengths_X = batch\n",
        "  pred_Y = model(batch_X, lengths_X, max_length=20)\n",
        "  pred = pred_Y.max(dim=-1)[1].view(-1).data.cpu().tolist()\n",
        "  refs = batch_Y.view(-1).data.cpu().tolist()\n",
        "  refs_list.append(refs)\n",
        "  hyp_list.append(pred)\n",
        "bleu = calc_bleu(refs_list, hyp_list)\n",
        "print(bleu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt7VWkUgUFAK",
        "outputId": "a8a31a85-eab0-4faa-de82-3a5b9d8c5886"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19.409227762250016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beam Seach"
      ],
      "metadata": {
        "id": "idcqan4JUvbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BeamEncoderDecoder(EncoderDecoder):\n",
        "  '''\n",
        "  Beam Searchでdecodeを行うためのクラス\n",
        "  '''\n",
        "  def __init__(self, input_size, output_size, hidden_size, beam_size=4):\n",
        "    '''\n",
        "    :param input_size: int, 入力言語の語彙数\n",
        "    :param output_size: int, 出力言語の語彙数\n",
        "    :param hidden_size: int, 隠れ層のユニット数\n",
        "    :param beam_size: int, ビーム数\n",
        "    '''\n",
        "    super(BeamEncoderDecoder, self).__init__(input_size, output_size, hidden_size)\n",
        "    self.beam_size = beam_size\n",
        "\n",
        "  def forward(self, batch_X, lengths_X, max_length):\n",
        "    '''\n",
        "    :param batch_X: tensor, 入力系列のバッチ, size=(max_length, batch_size)\n",
        "    :param lengths_X: list, 入力系列のバッチ内の各サンプルの文長\n",
        "    :param max_length: int, Decoderの最大文長\n",
        "    :return decoder_outputs: list, 各ビームのDecoderの出力\n",
        "    :return finished_scores: list of float, 各ビームのスコア\n",
        "    '''\n",
        "    _, encoder_hidden = self.encoder(batch_X, lengths_X)\n",
        "\n",
        "    # decoderの入力と隠れ層の初期状態を定義\n",
        "    decoder_input = torch.tensor([BOS] * self.beam_size, dtype=torch.long, device=device)\n",
        "    decoder_input = decoder_input.unsqueeze(0)  # (1, batch_size)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    # beam_sizeの数だけrepeatする\n",
        "    decoder_input = decoder_input.expand(1, beam_size)\n",
        "    decoder_hidden = decoder_hidden.expand(1, beam_size, -1).contiguous()\n",
        "\n",
        "    k = beam_size\n",
        "    finished_beams = []\n",
        "    finished_scores = []\n",
        "    prev_probs = torch.zeros(beam_size, 1, dtype=torch.float, device=device)  # 前の時刻の各ビームの対数尤度を保持\n",
        "    output_size = self.decoder.output_size\n",
        "\n",
        "    # 各時刻ごとに処理\n",
        "    for t in range(max_length):\n",
        "      # decoder_input: (1, k)\n",
        "      decoder_output, decoder_hidden = self.decoder(decoder_input[-1:], decoder_hidden)\n",
        "      # decoder_output: (1, k, output_size)\n",
        "      # decoder_hidden: (1, k, hidden_size)\n",
        "      decoder_output_t = decoder_output[-1]  # (k, output_size)\n",
        "      log_probs = prev_probs + F.log_softmax(decoder_output_t, dim=-1)  # (k, output_size)\n",
        "      scores = log_probs  # 対数尤度をスコアとする\n",
        "\n",
        "      # スコアの高いビームとその単語を取得\n",
        "      flat_scores = scores.view(-1)  # (k*output_size,)\n",
        "      if t == 0:\n",
        "        flat_scores = flat_scores[:output_size]  # t=0のときは後半の同じ値の繰り返しを除外\n",
        "      top_vs, top_is = flat_scores.data.topk(k)\n",
        "      beam_indices = top_is / output_size  # (k,)\n",
        "      word_indices = top_is % output_size  # (k,)\n",
        "      \n",
        "      # ビームを更新する\n",
        "      _next_beam_indices = []\n",
        "      _next_word_indices = []\n",
        "      for b, w in zip(beam_indices, word_indices):\n",
        "        if w.item() == EOS:  # EOSに到達した場合はそのビームは更新して終了\n",
        "          k -= 1\n",
        "          beam = torch.cat([decoder_input.t()[b], w.view(1,)])  # (t+2,)\n",
        "          score = scores[b, w].item()\n",
        "          finished_beams.append(beam)\n",
        "          finished_scores.append(score)\n",
        "        else:  # それ以外の場合はビームを更新\n",
        "          _next_beam_indices.append(b)\n",
        "          _next_word_indices.append(w)\n",
        "      if k == 0:\n",
        "        break\n",
        "\n",
        "      # tensorに変換\n",
        "      next_beam_indices = torch.tensor(_next_beam_indices, device=device)\n",
        "      next_word_indices = torch.tensor(_next_word_indices, device=device)\n",
        "\n",
        "      # 次の時刻のDecoderの入力を更新\n",
        "      decoder_input = torch.index_select(decoder_input, dim=-1, index=next_beam_indices)\n",
        "      decoder_input = torch.cat([decoder_input, next_word_indices.unsqueeze(0)], dim=0)\n",
        "\n",
        "      # 次の時刻のDecoderの隠れ層を更新\n",
        "      decoder_hidden = torch.index_select(decoder_hidden, dim=1, index=next_beam_indices)\n",
        "\n",
        "      # 各ビームの対数尤度を更新\n",
        "      flat_probs = log_probs.view(-1)  # (k*output_size,)\n",
        "      next_indices = (next_beam_indices + 1) * next_word_indices\n",
        "      prev_probs = torch.index_select(flat_probs, dim=0, index=next_indices).unsqueeze(1)  # (k, 1)\n",
        "\n",
        "    # すべてのビームが完了したらデータを整形\n",
        "    decoder_outputs = [[idx.item() for idx in beam[1:-1]] for beam in finished_beams]\n",
        "    \n",
        "    return decoder_outputs, finished_scores"
      ],
      "metadata": {
        "id": "zZpV99tZUybT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習済みモデルの読み込み\n",
        "beam_size = 3\n",
        "beam_model = BeamEncoderDecoder(**model_args, beam_size=beam_size).to(device)\n",
        "beam_model.load_state_dict(ckpt)\n",
        "beam_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ4KfeWpV_jN",
        "outputId": "f3e57f7c-c875-47cf-aed2-bd64d6c9151b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BeamEncoderDecoder(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(3725, 256, padding_idx=0)\n",
              "    (gru): GRU(256, 256)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(4405, 256, padding_idx=0)\n",
              "    (gru): GRU(256, 256)\n",
              "    (out): Linear(in_features=256, out_features=4405, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# テスト用データセットをロード\n",
        "test_dataloader = DataLoader(test_X, test_Y, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "t7n5PwoQV_gl"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 生成\n",
        "batch_X, batch_Y, lengths_X = next(test_dataloader)\n",
        "sentence_X = ' '.join(ids_to_sentence(vocab_X, batch_X.data.cpu().numpy()[:-1, 0]))\n",
        "sentence_Y = ' '.join(ids_to_sentence(vocab_Y, batch_Y.data.cpu().numpy()[:-1, 0]))\n",
        "print('src: {}'.format(sentence_X))\n",
        "print('tgt: {}'.format(sentence_Y))\n",
        "\n",
        "# 普通のdecode\n",
        "output = model(batch_X, lengths_X, max_length=20)\n",
        "output = output.max(dim=-1)[1].view(-1).data.cpu().tolist()\n",
        "output_sentence = ' '.join(ids_to_sentence(vocab_Y, trim_eos(output)))\n",
        "print('out: {}'.format(output_sentence))\n",
        "\n",
        "# beam decode\n",
        "outputs, scores = beam_model(batch_X, lengths_X, max_length=20)\n",
        "# scoreの良い順にソート\n",
        "outputs, scores = zip(*sorted(zip(outputs, scores), key=lambda x: -x[1]))\n",
        "for o, output in enumerate(outputs):\n",
        "  output_sentence = ' '.join(ids_to_sentence(vocab_Y, output))\n",
        "  print('out{}: {}'.format(o+1, output_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up9cYxAMV_IW",
        "outputId": "3250316e-1483-46a2-f52c-e97fd2882c85"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src: show your own business .\n",
            "tgt: 自分 の 事 を しろ 。\n",
            "out: 自分 の 仕事 を を し て い 。 。\n",
            "out1: 自分 の 持ち物 に <UNK> し て い 。\n",
            "out2: 自分 の 持ち物 に <UNK> し て い い 。\n",
            "out3: 自分 の 持ち物 に <UNK> し て い 。 。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UqETODNKh5WR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}